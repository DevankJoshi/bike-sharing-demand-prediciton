# -*- coding: utf-8 -*-
"""Bikes Sharing demand.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gg9ylfe1pqQxiOILAynp57ZLjgzf8aug
"""

import warnings
warnings.filterwarnings("ignore")

"""## 1. Data UnderStanding and Explorarion"""

# import libraries
import pandas as pd
import numpy as np

# reading the data
dataset = pd.read_csv('bike_sharing_data.csv')

dataset.head()

dataset.shape

dataset.columns

dataset.describe()

dataset.info()

# assigning string values to numerical data for seasons
# 1 - spring, 2 - summer, 3 - fall, 4 - winter
dataset['season'] = dataset.season.map({1: 'spring', 2: 'summer', 3: 'fall', 4: 'winter'})
dataset.season.unique()

dataset['season'].astype('category').value_counts()

# 0 - 2018, 1 - 2019
dataset['yr'].astype('category').value_counts()

# assigning string values to numerical data for months
def to_month(x):
    return x.map({1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'})

dataset['mnth'] = to_month(dataset.mnth)

dataset['mnth'].astype('category').value_counts()

dataset['holiday'].astype('category').value_counts()

def to_week_day(x):
    return x.map({1: 'Mon', 2: 'Tues', 3: 'Wed', 4: 'Thurs', 5: 'Fri', 6: 'Sat', 0: 'Sun'})

dataset['weekday'] = to_week_day(dataset.weekday)

dataset['weekday'].astype('category').value_counts()

dataset['workingday'].astype('category').value_counts()

# 1 - clear, fewCloud, partyCloud
# 2 - mist, cloudy,
# 3 - lightSnow, lightRainThunderstorm,
# assigning string values to numerical data for weathersit
dataset['weathersit'] = dataset.weathersit.map({1: 'A', 2: 'B', 3: 'C'})
dataset['weathersit'].astype('category').value_counts()

"""## 2. Data Visuilisation"""

# imorting libraries for visualization
import matplotlib.pyplot as plt
import seaborn as sns

# temperature
sns.histplot(dataset['temp'])
plt.show()

# actual temperature
sns.histplot(dataset['atemp'])
plt.show()

# windspeed
sns.histplot(dataset['windspeed'])
plt.show()

# target variable - count of total rental bikes including both casual and registered
sns.histplot(dataset['cnt'])
plt.show()

# converting date to datetime format
dataset['dteday'] = dataset['dteday'].astype('datetime64[ns]')

dataset['dteday'].head()

dataset_categorical = dataset.select_dtypes(exclude=['float64', 'datetime64','int64'])

dataset_categorical.columns

dataset_categorical

plt.figure(figsize=(20, 20))
plt.subplot(3,3,1)
sns.boxplot(x = 'season', y = 'cnt', data = dataset)
plt.subplot(3,3,2)
sns.boxplot(x = 'yr', y = 'cnt', data = dataset)
plt.subplot(3,3,3)
sns.boxplot(x = 'mnth', y = 'cnt', data = dataset)
plt.subplot(3,3,4)
sns.boxplot(x = 'holiday', y = 'cnt', data = dataset)
plt.subplot(3,3,5)
sns.boxplot(x = 'weekday', y = 'cnt', data = dataset)
plt.subplot(3,3,6)
sns.boxplot(x = 'workingday', y = 'cnt', data = dataset)
plt.subplot(3,3,7)
sns.boxplot(x = 'weathersit', y = 'cnt', data = dataset)
plt.tight_layout()
plt.show()

intvarlist = ["casual", "registered", "cnt"]
for var in intvarlist:
    dataset[var] = dataset[var].astype('float64')

dataset_numeric = dataset.select_dtypes(include=['float64'])

dataset_numeric.head()

sns.pairplot(dataset_numeric)
plt.show()

cor = dataset_numeric.corr()
cor

mask = np.array(cor)
mask[np.tril_indices_from(mask)] = False
fig, ax = plt.subplots()
fig.set_size_inches(10, 10)
sns.heatmap(cor, mask=mask, annot=True ,vmax=1, square=True)
plt.show()

# dropping atemp as it is highly correlated with temp
dataset.drop(['atemp'], axis = 1 ,inplace=True)

dataset.head()

"""## 3. Data Prepration"""

dataset_categorical = dataset.select_dtypes(include=['object'])

dataset_categorical.head()

dataset_dummy = pd.get_dummies(dataset_categorical, drop_first=True).astype(int)
dataset_dummy.head()

# drop categorical variables
dataset = dataset.drop(list(dataset_categorical.columns), axis = 1)
dataset

# append dummy variables
dataset = pd.concat([dataset, dataset_dummy], axis = 1)
dataset.head()

dataset = dataset.drop(['instant', 'dteday'], axis = 1, inplace=False)
dataset.head()

"""## 4. Model Building and Eval"""

# import libs
from sklearn import linear_model
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import statsmodels.api as sm
from sklearn.feature_selection import RFE

# spilitting the data
np.random.seed(0)
df_train, df_test = train_test_split(dataset, train_size = 0.7, test_size = 0.3, random_state = 100)

df_train

scaler = MinMaxScaler()

# apply scaler() to all the columns except the 'dummy' variables
var = ['temp', 'hum', 'windspeed', 'casual', 'registered', 'cnt']
df_train[var] = scaler.fit_transform(df_train[var])

df_train.describe()

# checking the correlation between variables after scaling
plt.figure(figsize = (30, 30))
sns.heatmap(df_train.corr(), annot = True, cmap="YlGnBu")

# diving into x and y
x_train = df_train.drop(['casual','registered','cnt'], axis = 1)
y_train = df_train['cnt']

x_train.head()

y_train.head()

np.array(x_train)

x_train_lm = sm.add_constant(x_train)
lr = sm.OLS(y_train, x_train_lm).fit()

lr.params

lm = LinearRegression()
lm.fit(x_train_lm, y_train)

print(lm.coef_)
print(lm.intercept_)

lr.summary()
lr.rsquared

rfe1 = RFE(estimator=lm, n_features_to_select=15)

rfe1.fit(x_train, y_train)

print(rfe1.support_)
print(rfe1.ranking_)

col1 = x_train.columns[rfe1.support_]

col1

x_train_rfe = x_train[col1]
x_train_rfe1 = sm.add_constant(x_train_rfe)
lm1 = sm.OLS(y_train, x_train_rfe1).fit()
lm1.summary()

lm1.rsquared

from statsmodels.stats.outliers_influence import variance_inflation_factor

a = x_train_rfe1.drop(['const'], axis = 1)

# evaluting VIF
vif = pd.DataFrame()
vif['Features'] = a.columns
vif['VIF'] = [variance_inflation_factor(a.values, i) for i in range(a.shape[1])]
vif['VIF'] = round(vif['VIF'], 2)
vif = vif.sort_values(by = "VIF", ascending = False)
vif

rfe2 = RFE(estimator=lm, n_features_to_select=7)

rfe2.fit(x_train, y_train)

print(rfe2.support_)
print(rfe2.ranking_)

col2 = x_train.columns[rfe2.support_]
col2

x_train_rfe2 = x_train[col2]
x_train_rfe2 = sm.add_constant(x_train_rfe2)
lr2 = sm.OLS(y_train, x_train_rfe2).fit()
lr2.summary()

lr2.rsquared

b = x_train_rfe2.drop(['const'], axis = 1)

# evaluting VIF
vif1 = pd.DataFrame()
vif1['Features'] = b.columns
vif1['VIF'] = [variance_inflation_factor(a.values, i) for i in range(b.shape[1])]
vif1['VIF'] = round(vif1['VIF'], 2)
vif1 = vif1.sort_values(by = "VIF", ascending = False)
vif1

y_train_cnt = lr2.predict(x_train_rfe2)

plt.figure()
sns.histplot((y_train - y_train_cnt), bins = 20)

df_test[var] = scaler.transform(df_test[var])

y_test = df_test['cnt']
x_test = df_test.drop(['casual','registered','cnt'], axis = 1)

x_test.head()

c = x_train_rfe2.drop(['const'], axis = 1)
col3 =  c.columns

x_test_rfe2 = x_test[col3]
x_test_rfe2 = sm.add_constant(x_test_rfe2)
x_test_rfe2.info()

y_pred = lr2.predict(x_test_rfe2)

plt.figure()
plt.scatter(y_test, y_pred)

from sklearn.metrics import r2_score
r2_score(y_test, y_pred)

plt.figure(figsize=(8,5))
sns.heatmap(dataset[col2].corr(),cmap='coolwarm',annot=True)
plt.show()

